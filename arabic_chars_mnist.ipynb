{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz/vxSnK+l8HybK9ifLeGj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nourm77/reader/blob/main/arabic_chars_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh\n"
      ],
      "metadata": {
        "id": "VjEY33mkD3Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"archive (4).zip\" -d /content/arabic-chars-mnist\n"
      ],
      "metadata": {
        "id": "kBFS-ZZOD5dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/arabic-chars-mnist\n"
      ],
      "metadata": {
        "id": "aMZXI2nlD5g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR  = '/content/arabic-chars-mnist'\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
        "TEST_DIR  = os.path.join(BASE_DIR, 'test')\n",
        "\n",
        "print(\"Train files:\", len(os.listdir(TRAIN_DIR)))\n",
        "print(\"Test  files:\", len(os.listdir(TEST_DIR)))\n"
      ],
      "metadata": {
        "id": "rwGV2LhIEhI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Gather all image files (adjust extensions if needed)\n",
        "train_paths = glob.glob(os.path.join(TRAIN_DIR, '*.*'))\n",
        "test_paths  = glob.glob(os.path.join(TEST_DIR,  '*.*'))\n",
        "\n",
        "# 2. Filter only common image formats\n",
        "train_paths = [p for p in train_paths if p.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "test_paths  = [p for p in test_paths  if p.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "\n",
        "print(f\"Found {len(train_paths)} train images and {len(test_paths)} test images\")\n",
        "\n",
        "# 3. Extract labels from filenames (e.g. 'alef12.png' → 'alef')\n",
        "def get_label(path):\n",
        "    fname = os.path.basename(path)\n",
        "    return re.split(r'(\\d+)', fname)[0]\n",
        "\n",
        "# 4. Build your DataFrames\n",
        "df_train = pd.DataFrame({\n",
        "    'path':  train_paths,\n",
        "    'label': [get_label(p) for p in train_paths]\n",
        "})\n",
        "df_test = pd.DataFrame({'path': test_paths})\n",
        "df_test['label'] = None  # unknown for test\n",
        "\n",
        "# 5. Inspect\n",
        "print(df_train.shape, df_test.shape)\n",
        "df_train.head()\n"
      ],
      "metadata": {
        "id": "IubykvMsEhL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/arabic-chars-mnist\n"
      ],
      "metadata": {
        "id": "AaqV_SnTEzH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get the sorted list of class names\n",
        "labels = sorted(df_train['label'].unique())\n",
        "\n",
        "# 2. Set up a row of subplots (one per class)\n",
        "fig, axes = plt.subplots(1, len(labels), figsize=(30, 12), squeeze=False)\n",
        "\n",
        "# 3. Sample and display one image for each label\n",
        "for i, lbl in enumerate(labels):\n",
        "    sample_path = df_train[df_train['label'] == lbl].sample(1)['path'].iloc[0]\n",
        "    img = cv2.imread(sample_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axes[0, i].imshow(img)\n",
        "    axes[0, i].set_title(lbl)\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zB0smWV5EhOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_images(df, size=(32,32)):\n",
        "    N = len(df)\n",
        "    X = np.empty((N, size[0], size[1], 3), dtype=np.uint8)\n",
        "    for i, path in enumerate(df['path']):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.resize(img, size)\n",
        "        X[i] = img\n",
        "    return X\n",
        "\n",
        "x_train = load_images(df_train)\n",
        "x_test  = load_images(df_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test  shape:', x_test.shape)\n"
      ],
      "metadata": {
        "id": "CMDQ9vRYFeNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert string labels → integer indices → one-hot vectors\n",
        "le = LabelEncoder()\n",
        "y_train_int = le.fit_transform(df_train['label'])\n",
        "y_train     = to_categorical(y_train_int, num_classes=len(le.classes_))\n",
        "\n",
        "print('Found classes:', le.classes_)\n",
        "print('y_train shape:', y_train.shape)\n"
      ],
      "metadata": {
        "id": "GptWDmhJFeRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, BatchNormalization,\n",
        "    Dropout, Flatten, Dense\n",
        ")\n",
        "\n",
        "def create_model(input_shape=(32,32,3), n_classes=28):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(2,2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu', kernel_regularizer='l2'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Instantiate and inspect\n",
        "model = create_model(n_classes=len(le.classes_))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "VAoNy6kRFeXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_split=0.3,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "OZFjgLCSFzjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "oaalyjrHFzqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "xUMEuF0bFzvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Predict class indices\n",
        "preds = model.predict(x_test)\n",
        "idxs = np.argmax(preds, axis=1)\n",
        "labels_pred = le.inverse_transform(idxs)\n",
        "\n",
        "# Show a few random examples\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "for ax in axes.flatten():\n",
        "    i = random.randint(0, len(x_test)-1)\n",
        "    img = cv2.cvtColor(x_test[i], cv2.COLOR_BGR2RGB)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(labels_pred[i])\n",
        "    ax.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3g4OnmDmFz7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Split off 20% for evaluation\n",
        "paths = df_train['path']\n",
        "labels= df_train['label']\n",
        "p_train, p_eval, y_train_lab, y_eval_lab = train_test_split(\n",
        "    paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Load & preprocess\n",
        "df_eval = pd.DataFrame({'path': p_eval})\n",
        "x_eval = load_images(df_eval)\n",
        "y_eval_int = le.transform(y_eval_lab)\n",
        "y_eval = to_categorical(y_eval_int, num_classes=len(le.classes_))\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(x_eval, y_eval, verbose=1)\n",
        "print(f\"Held-out accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "pmykQiKxFz_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "gen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "train_gen = gen.flow(x_train, y_train, batch_size=64, subset='training')\n",
        "val_gen   = gen.flow(x_train, y_train, batch_size=64, subset='validation')\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "Jd1vAVNcHomO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "img_path = '/content/arabic-chars-mnist/test/zain86.jpg'\n",
        "print(\"Exists?\", os.path.exists(img_path))\n",
        "print(\"Directory listing:\", os.listdir(os.path.dirname(img_path))[:10])\n"
      ],
      "metadata": {
        "id": "kRz8OQPjHopZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick one that actually shows up in the list\n",
        "test_file = '/content/arabic-chars-mnist/train/feh3518.jpg'\n",
        "print(predict_char(test_file, model, le))\n"
      ],
      "metadata": {
        "id": "9tQF7u0dHosw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_char('/content/arabic-chars-mnist/train/feh3518.jpg', model, le))\n"
      ],
      "metadata": {
        "id": "Omu26eNG6UaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4K4i0ox26Ud9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}